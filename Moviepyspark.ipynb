{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Label Classification - Movie Genre Prediction\n",
    "\n",
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init('/home/cse587/spark-2.4.0-bin-hadoop2.7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import *\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "   .appName(\"Assignment 3\") \\\n",
    "   .config(\"spark.some.config.option\", \"4gb\") \\\n",
    "   .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "sqlcontext=SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer, CountVectorizer\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "from pyspark.ml.feature import Word2Vec\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import LogisticRegressionModel\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "import os,sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('/home/cse587/train.csv')\n",
    "df = sqlcontext.createDataFrame(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmapping = pd.read_csv('/home/cse587/mapping.csv')\n",
    "colnames = ['Genrenumber','Genre']\n",
    "dfmapping.columns =colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleData = spark.read.load(\"/home/cse587/sample.csv\",format = \"csv\", sep = ',', inferSchema = 'true', header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.withColumn(\"plot\",F.lower(F.col('plot')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "regexTokenizer = RegexTokenizer(inputCol=\"plot\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "data = regexTokenizer.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stupwords =['t','despite','working','develop','whence', 'here', 'show', 'were', 'why', 'n’t', 'the', 'whereupon', 'not', 'more', 'how', 'eight', 'indeed', 'i', 'only', 'via', 'nine', 're', 'themselves', 'almost', 'to', 'already', 'front', 'least', 'becomes', 'thereby', 'doing', 'her', 'together', 'be', 'often', 'then', 'quite', 'less', 'many', 'they', 'ourselves', 'take', 'its', 'yours', 'each', 'would', 'may', 'namely', 'do', 'whose', 'whether', 'side', 'both', 'what', 'between', 'toward', 'our', 'whereby', \"'m\", 'formerly', 'myself', 'had', 'really', 'call', 'keep', \"'re\", 'hereupon', 'can', 'their', 'eleven', '’m', 'even', 'around', 'twenty', 'mostly', 'did', 'at', 'an', 'seems', 'serious', 'against', \"n't\", 'except', 'has', 'five', 'he', 'last', '‘ve', 'because', 'we', 'himself', 'yet', 'something', 'somehow', '‘m', 'towards', 'his', 'six', 'anywhere', 'us', '‘d', 'thru', 'thus', 'which', 'everything', 'become', 'herein', 'one', 'in', 'although', 'sometime', 'give', 'cannot', 'besides', 'across', 'noone', 'ever', 'that', 'over', 'among', 'during', 'however', 'when', 'sometimes', 'still', 'seemed', 'get', \"'ve\", 'him', 'with', 'part', 'beyond', 'everyone', 'same', 'this', 'latterly', 'no', 'regarding', 'elsewhere', 'others', 'moreover', 'else', 'back', 'alone', 'somewhere', 'are', 'will', 'beforehand', 'ten', 'very', 'most', 'three', 'former', '’re', 'otherwise', 'several', 'also', 'whatever', 'am', 'becoming', 'beside', '’s', 'nothing', 'some', 'since', 'thence', 'anyway', 'out', 'up', 'well', 'it', 'various', 'four', 'top', '‘s', 'than', 'under', 'might', 'could', 'by', 'too', 'and', 'whom', '‘ll', 'say', 'therefore', \"'s\", 'other', 'throughout', 'became', 'your', 'put', 'per', \"'ll\", 'fifteen', 'must', 'before', 'whenever', 'anyone', 'without', 'does', 'was', 'where', 'thereafter', \"'d\", 'another', 'yourselves', 'n‘t', 'see', 'go', 'wherever', 'just', 'seeming', 'hence', 'full', 'whereafter', 'bottom', 'whole', 'own', 'empty', 'due', 'behind', 'while', 'onto', 'wherein', 'off', 'again', 'a', 'two', 'above', 'therein', 'sixty', 'those', 'whereas', 'using', 'latter', 'used', 'my', 'herself', 'hers', 'or', 'neither', 'forty', 'thereupon', 'now', 'after', 'yourself', 'whither', 'rather', 'once', 'from', 'until', 'anything', 'few', 'into', 'such', 'being', 'make', 'mine', 'please', 'along', 'hundred', 'should', 'below', 'third', 'unless', 'upon', 'perhaps', 'ours', 'but', 'never', 'whoever', 'fifty', 'any', 'all', 'nobody', 'there', 'have', 'anyhow', 'of', 'seem', 'down', 'is', 'every', '’ll', 'much', 'none', 'further', 'me', 'who', 'nevertheless', 'about', 'everywhere', 'name', 'enough', '’d', 'next', 'meanwhile', 'though', 'through', 'on', 'first', 'been', 'hereby', 'if', 'move', 'so', 'either', 'amongst', 'for', 'twelve', 'nor', 'she', 'always', 'these', 'as', '’ve', 'amount', '‘re', 'someone', 'afterwards', 'you', 'nowhere', 'itself', 'done', 'hereafter', 'within', 'made', 'ca', 'them']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(movie_id=23890098, movie_name='Taxi Blues', plot=\"shlykov, a hard-working taxi driver and lyosha, a saxophonist, develop a bizarre love-hate relationship, and despite their prejudices, realize they aren't so different after all.\", genre=\"['World cinema', 'Drama']\", words=['shlykov', 'a', 'hard', 'working', 'taxi', 'driver', 'and', 'lyosha', 'a', 'saxophonist', 'develop', 'a', 'bizarre', 'love', 'hate', 'relationship', 'and', 'despite', 'their', 'prejudices', 'realize', 'they', 'aren', 't', 'so', 'different', 'after', 'all'], filtered=['shlykov', 'hard', 'taxi', 'driver', 'lyosha', 'saxophonist', 'bizarre', 'love', 'hate', 'relationship', 'prejudices', 'realize', 'aren', 'different'])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\" ).setStopWords(stupwords)\n",
    "data = remover.transform(data)\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['movie_id', 'movie_name', 'plot', 'genre', 'words', 'filtered']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Drama',\n",
       " 'Comedy',\n",
       " 'Romance Film',\n",
       " 'Thriller',\n",
       " 'Action',\n",
       " 'World cinema',\n",
       " 'Crime Fiction',\n",
       " 'Horror',\n",
       " 'Black-and-white',\n",
       " 'Indie',\n",
       " 'Action/Adventure',\n",
       " 'Adventure',\n",
       " 'Family Film',\n",
       " 'Short Film',\n",
       " 'Romantic drama',\n",
       " 'Animation',\n",
       " 'Musical',\n",
       " 'Science Fiction',\n",
       " 'Mystery',\n",
       " 'Romantic comedy']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genrelist = dfmapping['Genre'].tolist()\n",
    "genrelist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|movie_id|          movie_name|                plot|               genre|               words|            filtered|            features|\n",
      "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|23890098|          Taxi Blues|shlykov, a hard-w...|['World cinema', ...|[shlykov, a, hard...|[shlykov, hard, t...|(5000,[8,107,449,...|\n",
      "|31186339|    The Hunger Games|the nation of pan...|['Action/Adventur...|[the, nation, of,...|[nation, panem, c...|(5000,[0,4,5,8,12...|\n",
      "|20663735|          Narasimham|poovalli induchoo...|['Musical', 'Acti...|[poovalli, induch...|[poovalli, induch...|(5000,[0,1,6,8,16...|\n",
      "| 2231378|  The Lemon Drop Kid|the lemon drop ki...|          ['Comedy']|[the, lemon, drop...|[lemon, drop, kid...|(5000,[0,5,7,9,12...|\n",
      "|  595909|   A Cry in the Dark|seventh-day adven...|['Crime Fiction',...|[seventh, day, ad...|[seventh, day, ad...|(5000,[0,6,7,11,1...|\n",
      "| 5272176|            End Game|the president is ...|['Action/Adventur...|[the, president, ...|[president, way, ...|(5000,[0,2,3,9,10...|\n",
      "| 1952976|          Dark Water|{{plot}} the film...|['Thriller', 'Dra...|[plot, the, film,...|[plot, film, open...|(5000,[0,1,2,4,5,...|\n",
      "|24225279|                Sing|the story begins ...|           ['Drama']|[the, story, begi...|[story, begins, h...|(5000,[0,3,5,9,15...|\n",
      "| 2462689|       Meet John Doe|infuriated at bei...|['Black-and-white...|[infuriated, at, ...|[infuriated, told...|(5000,[0,2,7,23,2...|\n",
      "|20532852|Destination Meatball|a line of people ...|['Animation', 'Sh...|[a, line, of, peo...|[line, people, dr...|(5000,[0,23,30,64...|\n",
      "|15401493|    Husband for Hire|lola  attempts to...|          ['Comedy']|[lola, attempts, ...|[lola, attempts, ...|(5000,[0,1,2,5,7,...|\n",
      "|18188932|         Up and Down|milan and goran a...|['Crime Fiction',...|[milan, and, gora...|[milan, goran, cr...|(5000,[11,24,93,9...|\n",
      "| 2940516|Ghost In The Noon...|bumbling pirate c...|          ['Comedy']|[bumbling, pirate...|[bumbling, pirate...|(5000,[0,2,3,12,2...|\n",
      "| 1480747|       House Party 2|{{plot}} followin...|          ['Comedy']|[plot, following,...|[plot, following,...|(5000,[0,1,4,5,7,...|\n",
      "|24448645|Forest of the Dam...|despite lucy's re...|          ['Horror']|[despite, lucy, s...|[lucy, s, reserva...|(5000,[0,6,42,57,...|\n",
      "|15072401|Charlie Chan's Se...|alan colby, heir ...|['Crime Fiction',...|[alan, colby, hei...|[alan, colby, hei...|(5000,[3,11,49,71...|\n",
      "| 4018288|     The Biggest Fan|debbie's favorite...|           ['Drama']|[debbie, s, favor...|[debbie, s, favor...|(5000,[0,5,19,20,...|\n",
      "| 4596602|      Ashes to Ashes|ashes to ashes is...|['Crime Fiction',...|[ashes, to, ashes...|[ashes, ashes, se...|(5000,[0,2,6,12,2...|\n",
      "|15224586|        Green Dragon|the film follows ...|  ['Indie', 'Drama']|[the, film, follo...|[film, follows, e...|(5000,[0,2,8,12,1...|\n",
      "|15585766|  The Rats of Tobruk|three friends are...|           ['Drama']|[three, friends, ...|[friends, droving...|(5000,[0,7,8,35,3...|\n",
      "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "countVectors = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\",minDF=20,vocabSize=5000)\n",
    "data1 = countVectors.fit(data)\n",
    "rescaledData = data1.transform(data)\n",
    "rescaledData.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def mapper(rows):\n",
    "    genrevalues=[0]*20\n",
    "    rows = rows.strip('][').split(', ') \n",
    "    for i in rows:   \n",
    "        for x,y in dfmapping.iterrows():\n",
    "            if i == ('\\''+ y['Genre'] +'\\''):\n",
    "                genrevalues[x] = 1\n",
    "                continue\n",
    "    return str(genrevalues).strip('][\\,').replace(\" \",\"\")\n",
    "ildpd = udf(mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescaledData = rescaledData.withColumn(\"label\",ildpd('genre'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeldata = rescaledData.select(\"movie_id\",\"features\",\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_col = pyspark.sql.functions.split(modeldata['label'],',')\n",
    "for i in range(0,20):\n",
    "    modeldata = modeldata.withColumn(genrelist[i],split_col.getItem(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+-----+------+------------+--------+------+------------+-------------+------+---------------+-----+----------------+---------+-----------+----------+--------------+---------+-------+---------------+-------+---------------+\n",
      "|movie_id|            features|               label|Drama|Comedy|Romance Film|Thriller|Action|World cinema|Crime Fiction|Horror|Black-and-white|Indie|Action/Adventure|Adventure|Family Film|Short Film|Romantic drama|Animation|Musical|Science Fiction|Mystery|Romantic comedy|\n",
      "+--------+--------------------+--------------------+-----+------+------------+--------+------+------------+-------------+------+---------------+-----+----------------+---------+-----------+----------+--------------+---------+-------+---------------+-------+---------------+\n",
      "|23890098|(5000,[8,107,449,...|1,0,0,0,0,1,0,0,0...|    1|     0|           0|       0|     0|           1|            0|     0|              0|    0|               0|        0|          0|         0|             0|        0|      0|              0|      0|              0|\n",
      "|31186339|(5000,[0,4,5,8,12...|1,0,0,0,1,0,0,0,0...|    1|     0|           0|       0|     1|           0|            0|     0|              0|    0|               1|        0|          0|         0|             0|        0|      0|              1|      0|              0|\n",
      "|20663735|(5000,[0,1,6,8,16...|1,0,0,0,1,0,0,0,0...|    1|     0|           0|       0|     1|           0|            0|     0|              0|    0|               0|        0|          0|         0|             0|        0|      1|              0|      0|              0|\n",
      "| 2231378|(5000,[0,5,7,9,12...|0,1,0,0,0,0,0,0,0...|    0|     1|           0|       0|     0|           0|            0|     0|              0|    0|               0|        0|          0|         0|             0|        0|      0|              0|      0|              0|\n",
      "|  595909|(5000,[0,6,7,11,1...|1,0,0,0,0,1,1,0,0...|    1|     0|           0|       0|     0|           1|            1|     0|              0|    0|               0|        0|          0|         0|             0|        0|      0|              0|      0|              0|\n",
      "+--------+--------------------+--------------------+-----+------+------------+--------+------+------------+-------------+------+---------------+-----+----------------+---------+-----------+----------+--------------+---------+-------+---------------+-------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modeldata.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "testingdata = pd.read_csv('/home/cse587/test.csv')\n",
    "testingdata = sqlcontext.createDataFrame(testingdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "testingdata= testingdata.withColumn(\"plot\",F.lower(F.col('plot')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "regexTokenizer11 = RegexTokenizer(inputCol=\"plot\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "testingdf = regexTokenizer11.transform(testingdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\" ).setStopWords(stupwords)\n",
    "testingdf = remover.transform(testingdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|movie_id|          movie_name|                plot|               words|            filtered|            features|\n",
      "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| 1335380|              Exodus|the film is based...|[the, film, is, b...|[film, based, eve...|(5000,[0,1,2,5,6,...|\n",
      "|29062594|A la salida nos v...|a group of teenag...|[a, group, of, te...|[group, teenagers...|(5000,[5,6,44,57,...|\n",
      "| 9252321|   Come Back, Africa|this story of a z...|[this, story, of,...|[story, zulu, fam...|(5000,[0,3,5,9,11...|\n",
      "|13455076|       A Merry Mixup|the stooges play ...|[the, stooges, pl...|[stooges, play, s...|(5000,[67,69,70,8...|\n",
      "|24165951|        Getting Even|a soldier-of-fort...|[a, soldier, of, ...|[soldier, fortune...|(5000,[0,13,320,3...|\n",
      "| 1925869|  River of No Return|set in the northw...|[set, in, the, no...|[set, northwester...|(5000,[0,1,2,3,4,...|\n",
      "|10799612|          Amici miei|like in many othe...|[like, in, many, ...|[like, monicelli,...|(5000,[0,2,4,6,8,...|\n",
      "|28238240|Mickey's Big Game...|mickey and the sc...|[mickey, and, the...|[mickey, scorpion...|(5000,[12,155,188...|\n",
      "|17124781|The Good, the Bad...|in the desert wil...|[in, the, desert,...|[desert, wilderne...|(5000,[0,3,7,12,2...|\n",
      "|28207941|    The Dancing Fool|bimbo and koko ar...|[bimbo, and, koko...|[bimbo, koko, sig...|(5000,[0,38,44,17...|\n",
      "|19174305|              Tahaan|tahaan  lives wit...|[tahaan, lives, w...|[tahaan, lives, g...|(5000,[0,1,3,5,9,...|\n",
      "|18392317|     Mysterious Mose|betty is startled...|[betty, is, start...|[betty, startled,...|(5000,[0,2,5,10,2...|\n",
      "|34420857|Kelviyum Naane Pa...|nirmal ([[karthik...|[nirmal, karthik,...|[nirmal, karthik,...|(5000,[0,1,4,8,14...|\n",
      "| 4039635|   First on the Moon|a group of journa...|[a, group, of, jo...|[group, journalis...|(5000,[0,2,22,30,...|\n",
      "| 8034072|  Journey of a Woman|vaibhavari sahay,...|[vaibhavari, saha...|[vaibhavari, saha...|(5000,[0,1,6,8,9,...|\n",
      "| 4016437|     Sophie's Choice|in 1947, the movi...|[in, 1947, the, m...|[1947, movie, s, ...|(5000,[0,1,4,8,14...|\n",
      "| 1520023|  Ninja Resurrection|ninja resurrectio...|[ninja, resurrect...|[ninja, resurrect...|(5000,[0,1,3,4,5,...|\n",
      "|24589422|      Maria’s Lovers|in the spring of ...|[in, the, spring,...|[spring, 1946, iv...|(5000,[0,1,4,5,6,...|\n",
      "|35068740|           Chinnavar|muthu ([[prabhu  ...|[muthu, prabhu, a...|[muthu, prabhu, v...|(5000,[0,8,15,22,...|\n",
      "|21132951|              Aparan|vishwanathan , an...|[vishwanathan, an...|[vishwanathan, in...|(5000,[0,1,3,6,8,...|\n",
      "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rescaledDatatest = data1.transform(testingdf)\n",
    "rescaledDatatest.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "result =pd.DataFrame()\n",
    "result['movie_id'] = [int(i.movie_id) for i in rescaledDatatest.collect()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count vectorizer model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,20):\n",
    "    genredatatrain  = modeldata.select(\"features\",genrelist[i])\n",
    "    genredatatrain = genredatatrain.withColumnRenamed(genrelist[i],\"label\")\n",
    "    genredatatrain = genredatatrain.withColumn('label',genredatatrain['label'].cast(IntegerType())) \n",
    "\n",
    "    lr = LogisticRegression(maxIter=20,featuresCol= 'features', labelCol = 'label')\n",
    "    lrModel = lr.fit(genredatatrain)\n",
    "    lrModel.save('/home/cse587/pert1/'+'model'+str(i+1))\n",
    "\n",
    "    print(\"over\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test prediction count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,20):\n",
    "    lrModeltest = LogisticRegressionModel.load('/home/cse587/pert1/'+'model'+str(i+1))\n",
    "    predictions = lrModeltest.transform(rescaledDatatest)\n",
    "    predictionvalues = [int(j.prediction) for j in predictions.collect()]\n",
    "    result[genrelist[i]] = predictionvalues\n",
    "    \n",
    "    print(\"over\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "resulTm1 = pd.DataFrame()\n",
    "resulTm1['movie_id'] = result['movie_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1335380</td>\n",
       "      <td>1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29062594</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9252321</td>\n",
       "      <td>1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13455076</td>\n",
       "      <td>0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24165951</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>32038154</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>15127637</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>9119884</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>859241</td>\n",
       "      <td>1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1475914</td>\n",
       "      <td>1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    movie_id                              Predictions\n",
       "0    1335380  1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "1   29062594  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "2    9252321  1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
       "3   13455076  0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "4   24165951  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "..       ...                                      ...\n",
       "95  32038154  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "96  15127637  0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
       "97   9119884  0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0\n",
       "98    859241  1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "99   1475914  1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resulTm1['Predictions'] = result[genrelist].apply(lambda x: ' '.join(x.values.astype(str)),axis=1) \n",
    "resulTm1.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "resulTm1.to_csv('a3part1.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|movie_id|          movie_name|                plot|               genre|               words|            filtered|         rawFeatures|            features|\n",
      "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|23890098|          Taxi Blues|shlykov, a hard-w...|['World cinema', ...|[shlykov, a, hard...|[shlykov, hard, t...|(10000,[135,719,1...|(10000,[135,719,1...|\n",
      "|31186339|    The Hunger Games|the nation of pan...|['Action/Adventur...|[the, nation, of,...|[nation, panem, c...|(10000,[26,47,66,...|(10000,[26,47,66,...|\n",
      "|20663735|          Narasimham|poovalli induchoo...|['Musical', 'Acti...|[poovalli, induch...|[poovalli, induch...|(10000,[52,74,104...|(10000,[52,74,104...|\n",
      "| 2231378|  The Lemon Drop Kid|the lemon drop ki...|          ['Comedy']|[the, lemon, drop...|[lemon, drop, kid...|(10000,[52,76,77,...|(10000,[52,76,77,...|\n",
      "|  595909|   A Cry in the Dark|seventh-day adven...|['Crime Fiction',...|[seventh, day, ad...|[seventh, day, ad...|(10000,[91,137,15...|(10000,[91,137,15...|\n",
      "| 5272176|            End Game|the president is ...|['Action/Adventur...|[the, president, ...|[president, way, ...|(10000,[52,158,20...|(10000,[52,158,20...|\n",
      "| 1952976|          Dark Water|{{plot}} the film...|['Thriller', 'Dra...|[plot, the, film,...|[plot, film, open...|(10000,[104,140,1...|(10000,[104,140,1...|\n",
      "|24225279|                Sing|the story begins ...|           ['Drama']|[the, story, begi...|[story, begins, h...|(10000,[17,24,76,...|(10000,[17,24,76,...|\n",
      "| 2462689|       Meet John Doe|infuriated at bei...|['Black-and-white...|[infuriated, at, ...|[infuriated, told...|(10000,[1,67,78,1...|(10000,[1,67,78,1...|\n",
      "|20532852|Destination Meatball|a line of people ...|['Animation', 'Sh...|[a, line, of, peo...|[line, people, dr...|(10000,[364,841,8...|(10000,[364,841,8...|\n",
      "|15401493|    Husband for Hire|lola  attempts to...|          ['Comedy']|[lola, attempts, ...|[lola, attempts, ...|(10000,[76,100,15...|(10000,[76,100,15...|\n",
      "|18188932|         Up and Down|milan and goran a...|['Crime Fiction',...|[milan, and, gora...|[milan, goran, cr...|(10000,[76,468,99...|(10000,[76,468,99...|\n",
      "| 2940516|Ghost In The Noon...|bumbling pirate c...|          ['Comedy']|[bumbling, pirate...|[bumbling, pirate...|(10000,[50,410,61...|(10000,[50,410,61...|\n",
      "| 1480747|       House Party 2|{{plot}} followin...|          ['Comedy']|[plot, following,...|[plot, following,...|(10000,[52,104,13...|(10000,[52,104,13...|\n",
      "|24448645|Forest of the Dam...|despite lucy's re...|          ['Horror']|[despite, lucy, s...|[lucy, s, reserva...|(10000,[141,818,9...|(10000,[141,818,9...|\n",
      "|15072401|Charlie Chan's Se...|alan colby, heir ...|['Crime Fiction',...|[alan, colby, hei...|[alan, colby, hei...|(10000,[213,493,7...|(10000,[213,493,7...|\n",
      "| 4018288|     The Biggest Fan|debbie's favorite...|           ['Drama']|[debbie, s, favor...|[debbie, s, favor...|(10000,[230,433,6...|(10000,[230,433,6...|\n",
      "| 4596602|      Ashes to Ashes|ashes to ashes is...|['Crime Fiction',...|[ashes, to, ashes...|[ashes, ashes, se...|(10000,[164,277,3...|(10000,[164,277,3...|\n",
      "|15224586|        Green Dragon|the film follows ...|  ['Indie', 'Drama']|[the, film, follo...|[film, follows, e...|(10000,[273,306,3...|(10000,[273,306,3...|\n",
      "|15585766|  The Rats of Tobruk|three friends are...|           ['Drama']|[three, friends, ...|[friends, droving...|(10000,[207,213,4...|(10000,[207,213,4...|\n",
      "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
    "featurizedData = hashingTF.transform(data)\n",
    "\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\",minDocFreq=2)\n",
    "idfModel = idf.fit(featurizedData)\n",
    "idfdata = idfModel.transform(featurizedData)\n",
    "\n",
    "idfdata.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfdata = idfdata.withColumn(\"label\",ildpd('genre'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+\n",
      "|movie_id|            features|               label|\n",
      "+--------+--------------------+--------------------+\n",
      "|23890098|(10000,[135,719,1...|1,0,0,0,0,1,0,0,0...|\n",
      "|31186339|(10000,[26,47,66,...|1,0,0,0,1,0,0,0,0...|\n",
      "|20663735|(10000,[52,74,104...|1,0,0,0,1,0,0,0,0...|\n",
      "| 2231378|(10000,[52,76,77,...|0,1,0,0,0,0,0,0,0...|\n",
      "|  595909|(10000,[91,137,15...|1,0,0,0,0,1,1,0,0...|\n",
      "| 5272176|(10000,[52,158,20...|1,0,0,1,1,0,0,0,0...|\n",
      "| 1952976|(10000,[104,140,1...|1,0,0,1,0,0,0,1,0...|\n",
      "|24225279|(10000,[17,24,76,...|1,0,0,0,0,0,0,0,0...|\n",
      "| 2462689|(10000,[1,67,78,1...|1,1,1,0,0,0,0,0,1...|\n",
      "|20532852|(10000,[364,841,8...|0,0,0,0,0,0,0,0,0...|\n",
      "|15401493|(10000,[76,100,15...|0,1,0,0,0,0,0,0,0...|\n",
      "|18188932|(10000,[76,468,99...|1,1,0,0,0,1,1,0,0...|\n",
      "| 2940516|(10000,[50,410,61...|0,1,0,0,0,0,0,0,0...|\n",
      "| 1480747|(10000,[52,104,13...|0,1,0,0,0,0,0,0,0...|\n",
      "|24448645|(10000,[141,818,9...|0,0,0,0,0,0,0,1,0...|\n",
      "|15072401|(10000,[213,493,7...|0,0,0,1,0,0,1,1,0...|\n",
      "| 4018288|(10000,[230,433,6...|1,0,0,0,0,0,0,0,0...|\n",
      "| 4596602|(10000,[164,277,3...|0,0,1,1,1,0,1,0,0...|\n",
      "|15224586|(10000,[273,306,3...|1,0,0,0,0,0,0,0,0...|\n",
      "|15585766|(10000,[207,213,4...|1,0,0,0,0,0,0,0,0...|\n",
      "+--------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfidfmodaldata = tfidfdata.select(\"movie_id\",\"features\",\"label\")\n",
    "tfidfmodaldata.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_col = pyspark.sql.functions.split(tfidfmodaldata['label'],',')\n",
    "for i in range(0,20):\n",
    "    tfidfmodaldata = tfidfmodaldata.withColumn(genrelist[i],split_col.getItem(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|movie_id|          movie_name|                plot|               words|            filtered|         rawFeatures|            features|\n",
      "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| 1335380|              Exodus|the film is based...|[the, film, is, b...|[film, based, eve...|(10000,[58,92,158...|(10000,[58,92,158...|\n",
      "|29062594|A la salida nos v...|a group of teenag...|[a, group, of, te...|[group, teenagers...|(10000,[72,213,37...|(10000,[72,213,37...|\n",
      "| 9252321|   Come Back, Africa|this story of a z...|[this, story, of,...|[story, zulu, fam...|(10000,[69,177,23...|(10000,[69,177,23...|\n",
      "|13455076|       A Merry Mixup|the stooges play ...|[the, stooges, pl...|[stooges, play, s...|(10000,[324,493,7...|(10000,[324,493,7...|\n",
      "|24165951|        Getting Even|a soldier-of-fort...|[a, soldier, of, ...|[soldier, fortune...|(10000,[158,1549,...|(10000,[158,1549,...|\n",
      "| 1925869|  River of No Return|set in the northw...|[set, in, the, no...|[set, northwester...|(10000,[52,76,121...|(10000,[52,76,121...|\n",
      "|10799612|          Amici miei|like in many othe...|[like, in, many, ...|[like, monicelli,...|(10000,[33,36,177...|(10000,[33,36,177...|\n",
      "|28238240|Mickey's Big Game...|mickey and the sc...|[mickey, and, the...|[mickey, scorpion...|(10000,[87,2726,3...|(10000,[87,2726,3...|\n",
      "|17124781|The Good, the Bad...|in the desert wil...|[in, the, desert,...|[desert, wilderne...|(10000,[33,50,81,...|(10000,[33,50,81,...|\n",
      "|28207941|    The Dancing Fool|bimbo and koko ar...|[bimbo, and, koko...|[bimbo, koko, sig...|(10000,[205,285,3...|(10000,[205,285,3...|\n",
      "|19174305|              Tahaan|tahaan  lives wit...|[tahaan, lives, w...|[tahaan, lives, g...|(10000,[29,158,20...|(10000,[29,158,20...|\n",
      "|18392317|     Mysterious Mose|betty is startled...|[betty, is, start...|[betty, startled,...|(10000,[68,76,88,...|(10000,[68,76,88,...|\n",
      "|34420857|Kelviyum Naane Pa...|nirmal ([[karthik...|[nirmal, karthik,...|[nirmal, karthik,...|(10000,[121,711,7...|(10000,[121,711,7...|\n",
      "| 4039635|   First on the Moon|a group of journa...|[a, group, of, jo...|[group, journalis...|(10000,[26,64,65,...|(10000,[26,64,65,...|\n",
      "| 8034072|  Journey of a Woman|vaibhavari sahay,...|[vaibhavari, saha...|[vaibhavari, saha...|(10000,[158,201,3...|(10000,[158,201,3...|\n",
      "| 4016437|     Sophie's Choice|in 1947, the movi...|[in, 1947, the, m...|[1947, movie, s, ...|(10000,[147,153,3...|(10000,[147,153,3...|\n",
      "| 1520023|  Ninja Resurrection|ninja resurrectio...|[ninja, resurrect...|[ninja, resurrect...|(10000,[1,20,52,6...|(10000,[1,20,52,6...|\n",
      "|24589422|      Maria’s Lovers|in the spring of ...|[in, the, spring,...|[spring, 1946, iv...|(10000,[76,91,147...|(10000,[76,91,147...|\n",
      "|35068740|           Chinnavar|muthu ([[prabhu  ...|[muthu, prabhu, a...|[muthu, prabhu, v...|(10000,[452,763,8...|(10000,[452,763,8...|\n",
      "|21132951|              Aparan|vishwanathan , an...|[vishwanathan, an...|[vishwanathan, in...|(10000,[76,94,104...|(10000,[76,94,104...|\n",
      "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#hashingTF1 = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
    "featurizedDatatest = hashingTF.transform(testingdf)\n",
    "idfdatatest = idfModel.transform(featurizedDatatest)\n",
    "idfdatatest.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "resulttfidf =pd.DataFrame()\n",
    "resulttfidf['movie_id'] = [int(row.movie_id) for row in idfdatatest.collect()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,20):\n",
    "    genredatatraintfidf  = tfidfmodaldata.select(\"features\",genrelist[i])\n",
    "    genredatatraintfidf = genredatatraintfidf.withColumnRenamed(genrelist[i],\"label\")\n",
    "    genredatatraintfidf = genredatatraintfidf.withColumn('label',genredatatraintfidf['label'].cast(IntegerType())) \n",
    "\n",
    "    lr = LogisticRegression(maxIter=20,featuresCol= 'features', labelCol = 'label')\n",
    "    lrModel = lr.fit(genredatatraintfidf)\n",
    "    lrModel.save('/home/cse587/pert2/'+'model'+str(i+1))\n",
    "     \n",
    "    print(\"over\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data prediction TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,20):\n",
    "    lrModeltest = LogisticRegressionModel.load('/home/cse587/pert2/'+'model'+str(i+1))\n",
    "    predictionsidf = lrModeltest.transform(idfdatatest)\n",
    "    predictionvaluesidf = [int(j.prediction) for j in predictionsidf.collect()]\n",
    "    resulttfidf[genrelist[i]] = predictionvaluesidf\n",
    "    print(\"over\")\n",
    "        \n",
    "resulTmidf = pd.DataFrame()\n",
    "resulTmidf['movie_id'] = resulttfidf['movie_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1335380</td>\n",
       "      <td>1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29062594</td>\n",
       "      <td>1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9252321</td>\n",
       "      <td>1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13455076</td>\n",
       "      <td>0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24165951</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>32038154</td>\n",
       "      <td>1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>15127637</td>\n",
       "      <td>1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>9119884</td>\n",
       "      <td>0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>859241</td>\n",
       "      <td>1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1475914</td>\n",
       "      <td>1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    movie_id                              Predictions\n",
       "0    1335380  1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
       "1   29062594  1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "2    9252321  1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "3   13455076  0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "4   24165951  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "..       ...                                      ...\n",
       "95  32038154  1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "96  15127637  1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "97   9119884  0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0\n",
       "98    859241  1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "99   1475914  1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resulTmidf['Predictions'] = resulttfidf[genrelist].apply(lambda x: ' '.join(x.values.astype(str)),axis=1) \n",
    "resulTmidf.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "resulTmidf.to_csv('a3part2.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word2Vec = Word2Vec(vectorSize=300, minCount=10, inputCol=\"filtered\", outputCol=\"features\")\n",
    "modelword2vec = word2Vec.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultword2vec = modelword2vec.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vecdata = resultword2vec.withColumn(\"label\",ildpd('genre'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+\n",
      "|movie_id|            features|               label|\n",
      "+--------+--------------------+--------------------+\n",
      "|23890098|[-0.0216915629404...|1,0,0,0,0,1,0,0,0...|\n",
      "|31186339|[-0.0319842027231...|1,0,0,0,1,0,0,0,0...|\n",
      "|20663735|[0.04918256283331...|1,0,0,0,1,0,0,0,0...|\n",
      "| 2231378|[0.00883840547644...|0,1,0,0,0,0,0,0,0...|\n",
      "|  595909|[0.01200494910419...|1,0,0,0,0,1,1,0,0...|\n",
      "| 5272176|[0.02083711916696...|1,0,0,1,1,0,0,0,0...|\n",
      "| 1952976|[0.00507599805845...|1,0,0,1,0,0,0,1,0...|\n",
      "|24225279|[-0.0185899827124...|1,0,0,0,0,0,0,0,0...|\n",
      "| 2462689|[-0.0116721502407...|1,1,1,0,0,0,0,0,1...|\n",
      "|20532852|[-0.0548848330027...|0,0,0,0,0,0,0,0,0...|\n",
      "|15401493|[0.01417775396735...|0,1,0,0,0,0,0,0,0...|\n",
      "|18188932|[0.00123520172899...|1,1,0,0,0,1,1,0,0...|\n",
      "| 2940516|[-0.0163280593262...|0,1,0,0,0,0,0,0,0...|\n",
      "| 1480747|[-0.0255662851050...|0,1,0,0,0,0,0,0,0...|\n",
      "|24448645|[0.01823287077713...|0,0,0,0,0,0,0,1,0...|\n",
      "|15072401|[0.02659478455235...|0,0,0,1,0,0,1,1,0...|\n",
      "| 4018288|[-0.0031046616814...|1,0,0,0,0,0,0,0,0...|\n",
      "| 4596602|[0.02182520498445...|0,0,1,1,1,0,1,0,0...|\n",
      "|15224586|[0.02001327653767...|1,0,0,0,0,0,0,0,0...|\n",
      "|15585766|[0.03177407345806...|1,0,0,0,0,0,0,0,0...|\n",
      "+--------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "word2vecmodaldata = word2vecdata.select(\"movie_id\",\"features\",\"label\")\n",
    "word2vecmodaldata.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_col = pyspark.sql.functions.split(word2vecmodaldata['label'],',')\n",
    "for i in range(0,20):\n",
    "    word2vecmodaldata = word2vecmodaldata.withColumn(genrelist[i],split_col.getItem(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2Vectest = Word2Vec(vectorSize=100, minCount=0, inputCol=\"filtered\", outputCol=\"features\")\n",
    "#modelword2vectest = modelword2vec.fit(testingdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultword2vectest = modelword2vec.transform(testingdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|movie_id|          movie_name|                plot|               words|            filtered|            features|\n",
      "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| 1335380|              Exodus|the film is based...|[the, film, is, b...|[film, based, eve...|[0.02267053694794...|\n",
      "|29062594|A la salida nos v...|a group of teenag...|[a, group, of, te...|[group, teenagers...|[0.01691453481236...|\n",
      "| 9252321|   Come Back, Africa|this story of a z...|[this, story, of,...|[story, zulu, fam...|[0.01521266759014...|\n",
      "|13455076|       A Merry Mixup|the stooges play ...|[the, stooges, pl...|[stooges, play, s...|[-0.0382692396207...|\n",
      "|24165951|        Getting Even|a soldier-of-fort...|[a, soldier, of, ...|[soldier, fortune...|[-0.0127318286309...|\n",
      "| 1925869|  River of No Return|set in the northw...|[set, in, the, no...|[set, northwester...|[0.01422533534563...|\n",
      "|10799612|          Amici miei|like in many othe...|[like, in, many, ...|[like, monicelli,...|[0.01891455549862...|\n",
      "|28238240|Mickey's Big Game...|mickey and the sc...|[mickey, and, the...|[mickey, scorpion...|[-0.0603208721537...|\n",
      "|17124781|The Good, the Bad...|in the desert wil...|[in, the, desert,...|[desert, wilderne...|[-0.0180831669688...|\n",
      "|28207941|    The Dancing Fool|bimbo and koko ar...|[bimbo, and, koko...|[bimbo, koko, sig...|[-0.0134296208620...|\n",
      "|19174305|              Tahaan|tahaan  lives wit...|[tahaan, lives, w...|[tahaan, lives, g...|[-0.0027291725465...|\n",
      "|18392317|     Mysterious Mose|betty is startled...|[betty, is, start...|[betty, startled,...|[-0.0162888587920...|\n",
      "|34420857|Kelviyum Naane Pa...|nirmal ([[karthik...|[nirmal, karthik,...|[nirmal, karthik,...|[0.04163600555044...|\n",
      "| 4039635|   First on the Moon|a group of journa...|[a, group, of, jo...|[group, journalis...|[-0.0329150287676...|\n",
      "| 8034072|  Journey of a Woman|vaibhavari sahay,...|[vaibhavari, saha...|[vaibhavari, saha...|[0.02701252555296...|\n",
      "| 4016437|     Sophie's Choice|in 1947, the movi...|[in, 1947, the, m...|[1947, movie, s, ...|[0.04208614740933...|\n",
      "| 1520023|  Ninja Resurrection|ninja resurrectio...|[ninja, resurrect...|[ninja, resurrect...|[-0.0311570035252...|\n",
      "|24589422|      Maria’s Lovers|in the spring of ...|[in, the, spring,...|[spring, 1946, iv...|[0.05240816640624...|\n",
      "|35068740|           Chinnavar|muthu ([[prabhu  ...|[muthu, prabhu, a...|[muthu, prabhu, v...|[0.06489630696433...|\n",
      "|21132951|              Aparan|vishwanathan , an...|[vishwanathan, an...|[vishwanathan, in...|[0.03391375593674...|\n",
      "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resultword2vectest.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultword2vec =pd.DataFrame()\n",
    "resultword2vec['movie_id'] = [int(row.movie_id) for row in resultword2vectest.collect()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model and saving them in pert3 folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,20):\n",
    "    genredatatrainword2vec  = word2vecmodaldata.select(\"features\",genrelist[i])\n",
    "    genredatatrainword2vec = genredatatrainword2vec.withColumnRenamed(genrelist[i],\"label\")\n",
    "    genredatatrainword2vec = genredatatrainword2vec.withColumn('label',genredatatrainword2vec['label'].cast(IntegerType())) \n",
    "\n",
    "    lr = LogisticRegression(maxIter=20,featuresCol= 'features', labelCol = 'label')\n",
    "    lrModel = lr.fit(genredatatrainword2vec)\n",
    "    lrModel.save('/home/cse587/pert3/'+'model'+str(i+1))\n",
    "    \n",
    "    print(\"over\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model laoding for test data prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n",
      "over\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,20):\n",
    "    lrModel = LogisticRegressionModel.load('/home/cse587/pert3/'+'model'+str(i+1))\n",
    "    predictionsword2vec = lrModel.transform(resultword2vectest)\n",
    "    predictionvaluesword2vec = [int(j.prediction) for j in predictionsword2vec.collect()]\n",
    "    resultword2vec[genrelist[i]] = predictionvaluesword2vec\n",
    "    \n",
    "    print(\"over\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "resulTmword2vec11 = pd.DataFrame()\n",
    "resulTmword2vec11['movie_id'] = resultword2vec['movie_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1335380</td>\n",
       "      <td>1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29062594</td>\n",
       "      <td>1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9252321</td>\n",
       "      <td>1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13455076</td>\n",
       "      <td>1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24165951</td>\n",
       "      <td>0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>32038154</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>15127637</td>\n",
       "      <td>1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>9119884</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>859241</td>\n",
       "      <td>1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1475914</td>\n",
       "      <td>1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    movie_id                              Predictions\n",
       "0    1335380  1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "1   29062594  1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "2    9252321  1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "3   13455076  1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "4   24165951  0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "..       ...                                      ...\n",
       "95  32038154  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "96  15127637  1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "97   9119884  0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
       "98    859241  1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "99   1475914  1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resulTmword2vec11['Predictions'] = resultword2vec[genrelist].apply(lambda x: ' '.join(x.values.astype(str)),axis=1) \n",
    "resulTmword2vec11.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "resulTmword2vec11.to_csv('a3part3.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
